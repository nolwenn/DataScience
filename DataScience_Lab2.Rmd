---
title: "Science des Données - Lab 2"
author: "Nolwenn Le Meur & Pascal Crépey"
date: '`r format(Sys.time(), "%d %B, %Y")`'
output:
  unilur::tutorial_pdf: 
    number_sections: true
    toc: true
  unilur::answer_rmd: default
  unilur::tutorial_pdf_solution:
    number_sections: true
    toc: true
  unilur::tutorial_html_solution: default
  unilur::tutorial_html: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(data.table)
library(ggplot2)
library(readxl)
library(flextable)
library(dplyr)
theme_set(theme_minimal())
set_flextable_defaults(fonts_ignore=TRUE)

```

# Charger les données

Commencez par charger les données que vous avez sauvegardées lors du précédent atelier. Si vous avez bien les fichiers "baseLong.rds" et "baseAllHosp.rds", **utilisez la fonction `readRDS()` pour les lire**.

```{r readRDS, solution = TRUE, eval = TRUE}

baseLong <- readRDS("baseLong.rds")
baseAllHosp <- readRDS("baseAllHosp.rds")

```


# Créer une série temporelle à partir des données

Pour pouvoir être décomposée, la série temporelle doit être d'abord transformée en un objet spécial avec la fonction `ts()` à partir des données. Cette fonction permet d'inclure l'échelle de temps de la mesure dans les données.

Il faut cependant définir la période de temps qui vous intéresse. Cela se fait en définissant la fréquence d'échantillonage. Par exemple, si vous avez des données quotidiennes et que vous voulez définir la période de temps en semaine, alors vous indiquerez `frequency = 7`.

Par exemple (si `x` contient les valeurs pour chaque pas de temps).
 serie1 <- ts(x, frequency=7) 

Le paramètre `frequency` précise le nombre d'observations dans une période (i.e: 7 pour de l'hebdomadaire, 30.5 pour du mensuel, etc).


**Utilisez la fonction `ts()` pour créer une variable `hospit_ts` qui contiendra une série temporelle des hospitalisations avec une fenêtre hebdomadaire à partir de `baseLong`.**

```{r ts, solution = TRUE, eval = TRUE}

#en R de base
baseH <- baseLong[baseLong$type == "hospitalisation",]

#en dplyr
baseH <- baseLong  |> filter(type == "hospitalisation")

#en data.table
#baseH = baseLong[type=="hospitalisation",]

myts <- ts(baseH$valeur, 
          frequency = 7)

```

Cet objet `ts` est ensuite facilement exploitable par les outils de décomposition de séries temporelles. 

*Utilisez la fonction `decompose()` pour extraire la tendance, la saisonalité hebdomadaire et le résidu. Vous pouvez directement utiliser la fonction `plot()` sur cette décomposition.*

```{r decompose, solution = TRUE, eval=TRUE}

mydec <- decompose(myts, type = "additive")

plot(mydec)

```

# Visualiser une série temporelle avec ggplot

- Utilisez la *librarie ggplot* pour visualiser ces composantes sur un même graphique

```{r ggplotmydec, eval=TRUE}

baseH$tendance <- as.numeric(mydec$trend)
baseH$residu <- as.numeric(mydec$random)
baseH$saison <- as.numeric(mydec$seasonal)

ggplot(data = baseH, aes(x = date)) +
  geom_line(aes(y = tendance), color = "green") +
  geom_line(aes(y = residu), color = "red") +
  geom_line(aes(y = saison)) +
  geom_line(aes(y = valeur), alpha = 0.5)

```

**Que concluez-vous ?**

```{r, solution = TRUE}
# les variations hebdomadaires sont négligeables par rapport à la tendance. 
# Les variations "aléatoires" ne semblent pas l'être totalement et semblent 
# être plus importante lors des phases d'incidence forte 
#     -> processus multiplicatifs plutôt qu'additif.
```

## Changer l'agrégation temporelle

Pour changer l'agrégation temporelle de jour à semaine ou mois, il suffit de créer une nouvelle variable correspondant à cette unité de temps puis de sommer les valeurs quotidiennes pour chacune des valeurs de cette variable.

*Faites une agrégation par semaine et par mois.*

```{r aggr, solution = TRUE, eval=TRUE}

baseLong$mois <- format(baseLong$date, "%Y-%B")
baseLong$semaine <- format(baseLong$date, "%Y-%V")

baseLongAgg <- baseLong %>% group_by(mois, type) %>% mutate(valeur_mois = sum(valeur))

baseLongAgg <- baseLongAgg %>% group_by(semaine, type) %>% mutate(valeur_semaine = sum(valeur))


```

*Visualisez graphiquement ces nouvelles valeurs.*

```{r plotagg, solution  = TRUE, eval=TRUE}

ggplot(baseLongAgg, aes(x = date, linetype = type)) +
  geom_line(aes(y = valeur_mois), color = "green") +
  geom_line(aes(y = valeur_semaine), color = "red") + 
  scale_x_date(name = NULL) +
  scale_y_continuous(name = "incidence")


```

## Faire une moyenne glissante

Pour réaliser une moyenne glissante, vous pouvez utiliser des fonctions disponibles dans la librairie `zoo`, telle que `rollmean()`. L'argument k de cette fonction fixe la taille de la fenêtre. 

*Utilisez rollmean() pour calculer des moyennes glissantes avec des fenêtre de 7 jours ou de 30 jours. Visualisez les résultats et comparez aux résultats précédents.*

```{r rollmean, solution = TRUE, eval=TRUE}
library(zoo)

baseLongRmean <- baseLong %>% group_by(type) %>% 
  mutate(valeurM7 = rollmean(x = valeur, k = 7, fill = 0))

baseLongRmean <- baseLongRmean %>% group_by(type) %>% 
  mutate(valeurM30 = rollmean(x = valeur, k = 30, fill = 0))

ggplot(baseLongRmean, aes(x = date, linetype = type)) +
  geom_line(aes(y = valeur), color = "black")+
  geom_line(aes(y = valeurM7), color = "red")+
  geom_line(aes(y = valeurM30), color = "blue")+
  scale_x_date(name = NULL) 

```


# Réaliser des opérations et les présenter sous forme de tableau

## Réaliser une opération sur un sous-ensemble de données

La base baseAllHosp contient les données d'incidence journalière d'hospitalisation, de réanimation, de décès et de retour à domicile.

**Faites la somme par mois du nombre de nouvelles hospitalisations sur Paris. Pensez à créer une variable  *mois*, et utilisez la fonction `aggregate()` pour calculer cette somme. **

```{r sumByMonthParis, eval=FALSE, solution=TRUE}

URL <- "https://www.data.gouv.fr/fr/datasets/r/6fadff46-9efd-4c53-942a-54aca783c30c"

# data provenant de data.gouv.fr
baseAllHosp <- read.csv(URL, sep = ";")

# création de la variable date
baseAllHosp$date <- as.Date(baseAllHosp$jour)

# transformation des données
baseAllHosp$mois <- format(baseAllHosp$date, "%Y-%m")

sumByMonthParis <- aggregate(baseAllHosp$incid_hosp[baseAllHosp$dep == "75"], 
          by = list(mois = baseAllHosp$mois[baseAllHosp$dep == "75"]), 
          FUN = sum)

```

**Faites la même chose pour l'Ile-de-France (departements: 75, 77, 78, 91, 92, 93, 94, 95) en utilisant l'opérateur `%in%` **

```{r sumIdF, solution = TRUE}
sumByMonthIDF = aggregate(baseAllHosp$incid_hosp[baseAllHosp$dep %in% c("75", "77", "78", "91", "92", "93" , "94", "95") ], 
          by = list(mois = baseAllHosp$mois[baseAllHosp$dep %in% c("75", "77", "78", "91", "92", "93" , "94", "95")]), 
          FUN = sum)

```

Présentez les deux séries dans le même tableau. Vous pouvez rendre vos tableaux plus présentable en installant le package flextable et en utilisant la fonction du même nom dans ce package. 

**Rendre le tableau présentable avec flextable.**

```{r flextable, eval=TRUE}

dplyr::inner_join(sumByMonthParis, sumByMonthIDF, by = "mois") %>%
  flextable() %>%
  delete_part(part = "header") %>%
  add_header( mois = "Mois", x.x="Paris", x.y="IdF") %>%
  theme_booktabs()

```

# Cartographier des données

Les outils de cartographie sont de plus en plus utilisés en Science des données. 

Dans le logiciel *R* il existe de nombreux modules pour la représentation cartographique comme *ggmap*, *maps* ou *mapsf*. Pour une vue d'ensemble des lodumes disponibles sur CRAN vous pouve consulter la *Task View* associée (	https://CRAN.R-project.org/view=Spatial). 

Dans cet atelier nous vous proposons un exemple d'utilisation de [*mapsf*](https://rgeomatic.hypotheses.org/category/cartography).

Dans un premier temps, nous allons aggréger les incidences d'hospitalisation  avec l'instruction suivante. 

```{r, eval=FALSE}
sumByMonthDept <- aggregate(baseAllHosp$incid_hosp, 
          by = list(mois = baseAllHosp$mois, code_insee = baseAllHosp$dep), 
          FUN = sum)
names(sumByMonthDept)[3] <- "incidence"
```

**Quel est le niveau d'aggrégation ?**

```{r, solution = TRUE}

# Le niveau d'agrégation est le mois et le département.

```

Ensuite, nous allons avoir besoin de lire des fichiers *Shape* qui définissent à l'aide de polygones les frontrières géographiques. Pour se faire vous devrez télécharger et charger le package *sf*.  Puis, pour la représentation cartographique nous allons utliser le package *mapsf*.

```{r, eval=FALSE}

# Charger les libraries utiles
library(sf)
library(mapsf)

```

Nous allons lire les polygones géographiques des départements français. Pour ce faire vous devez télécharger les données sources soit sur le site de IGN ou le dossier departements-2017 (version simplifiée) sur https://github.com/nolwenn/DataScience. 

- Sauvegarder le dossier dans votre dossier de projet R.
- Utiliser les instructions ci-dessous pour lire le fichier shape
- Que font les différentes instructions?

```{r, eval=FALSE}
# Lire le fichier shape pour la France
FrMap <- st_read(dsn="departements-2017/.", quiet = TRUE)
FrMap$code_insee[FrMap$code_insee=="69D"] <- "69"

# Jointure avec les taux d'incidence
FrMap_incidence <- full_join( FrMap, sumByMonthDept, by="code_insee" )
```

Nous allons nous focaliser sur le mois de mars 2021. 

- Utiliser l'instruction ci-dessous pour filtrer les données.

```{r, echo=TRUE, eval=TRUE}
incidence_mars2021 <- FrMap_incidence %>% 
  dplyr::filter(mois == "2021-03")
```

- Utiliser la fonction *mf_map()* de la *library mapsf* pour faire une crate chorapleth de l'incidence de mars 2021. [Pensez à regarder l'aide de la fonction].

```{r, eval=TRUE}
mf_map(x = incidence_mars2021, var = "incidence", type = "choro")
```

- Refaire la même chose pour le mois d'octobre 2021

```{r, solution = TRUE, eval=TRUE}
incidence_oct2021 <- FrMap_incidence %>% 
  dplyr::filter(mois == "2021-10")
```

```{r, solution = TRUE, eval=TRUE}
mf_map(x = incidence_oct2021, 
       var = "incidence", 
       type = "choro",  
       nbreaks=6, 
       breaks = "jenks")
```

Vous pouvez remarquer que la carte n'est pas lisible puisque n'est pas centrer sur la France. Pour un focus sur la métropole, nous allons mettre à part les départements ultra-marins.

- Suivez les instructions ci-dessous pour se faire.

**Présentez la carte en retirant les départements ultra-marins.**

```{r sans ultra-marin, eval=TRUE}

ultra_marin <- grep("^97", incidence_oct2021$code_insee)
incidence_oct2021_metro <- incidence_oct2021[- ultra_marin, ]
```

- Refaire la représentation cartographique
- Sauvegarder votre carte

```{r carte sans ultra-marin, solution = TRUE, eval=TRUE}
mf_map(x = incidence_oct2021_metro, 
       var = "incidence", 
       type = "choro", 
       nbreaks=6, 
       breaks = "jenks",
       leg_val_rnd= 0,
       col = "brown4",
       leg_pos = "bottomleft2",  
       leg_title = "Incidence \n pour 100 000 pers.")

```

